\documentclass{sigchi}

% Use this command to override the default ACM copyright statement (e.g. for preprints). 
% Consult the conference website for the camera-ready copyright statement.
%% \toappear{
%% Permission to make digital or hard copies of all or part of this
%% work for personal or classroom use is granted without fee provided that 
%% copies are not made or distributed for profit or commercial advantage and
%% that copies bear this notice and the full citation on the first page. To
%% copy otherwise, or republish, to post on servers or to redistribute to 
%% lists, requires prior specific permission and/or a fee.\\
%{\confname{CHI'13}}, May 5--10, 2012, Austin, Texas, USA.\\
%Copyright 2012 ACM 978-1-4503-1015-4/12/05...\$10.00.
%}

\hyphenation{EPSRC SOCIAM}

\toappear{
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.\\
\emph{CHI 2013}, April 27--May 2, 2013, Paris, France.\\
Copyright 2013 ACM 978-1-4503-1899-0/13/04...\$15.00.}

% Arabic page numbers for submission. 
% Remove this line to eliminate page numbers for the camera ready copy
%\pagenumbering{arabic}


% Load basic packages
\usepackage{balance}  % to better equalise the last page
\usepackage{graphics} % for EPS, load graphicx instead
\usepackage{times}    % comment if you want LaTeX's default font
\usepackage{url}      % llt: nicely formatted URLs
\usepackage{multirow} % multirow tables

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\bf\ttfamily}}}
\makeatother
\urlstyle{leo}


% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, 
% to give it a fighting chance of not being over-written, 
% since its job is to redefine many LaTeX commands.
\usepackage[pdftex]{hyperref}
\hypersetup{
pdftitle={SIGCHI Conference Proceedings Format},
pdfauthor={LaTeX},
pdfkeywords={SIGCHI, proceedings, archival format},
bookmarksnumbered,
pdfstartview={FitH},
colorlinks,
citecolor=black,
filecolor=black,
linkcolor=black,
urlcolor=black,
breaklinks=true,
}

% create a shortcut to typeset table headings
\newcommand\tabhead[1]{\small\textbf{#1}}


% End of preamble. Here it comes the document.
\begin{document}

\title{Carp\'{e} Data: Supporting Serendipitous Data Integration in Personal Information Management}

\numberofauthors{1}
 \author{
   \alignauthor Max Van Kleek, Daniel A. Smith, Heather S. Packer, Jim Skinner, Nigel R. Shadbolt \\
     \affaddr{Web and Internet Science Research Group, Electronics and Computer Science}\\
     \affaddr{University of Southampton, Southampton, UK}\\
     \email{\{emax, ds, hp3, js40g09, nrs\}@ecs.soton.ac.uk}}

% Teaser figure can go here
%\teaser{
%  \centering
%  \includegraphics{Figure1}
%  \caption{Teaser Image}
%  \label{fig:teaser}
%}

\maketitle

\begin{abstract}
The information processing capabilities of humans enable them to opportunistically draw and integrate knowledge from nearly any information source.  However, the integration of digital, structured data from diverse sources remains difficult, due to problems of heterogeneity that arise when data modelled separately are brought together.  In this paper, we present an investigation of the feasibility of extending Personal Information Management (PIM) tools to support lightweight, user-driven mixing of previously un-integrated data, with the objective of allowing  users to take advantage of the emerging ecosystems of structured data currently becoming available.  In this study, we conducted an exploratory, sequential, mixed-method investigation, starting with two pre-studies of the data integration needs and challenges, respectively, of Web-based data sources. Observations from these pre-studies led to \emph{DataPalette}, an interface that introduced simple co-reference and group multi-path-selection mechanisms for working with terminologically and structurally heterogeneous data.  Our lab study showed, first, that participants readily understood the new interaction mechanisms which were introduced.  Secondly, participants made more carefully justified decisions, even while weighing a greater number of factors, moreover expending less effort, during subjective-choice tasks when using DataPalette, than with a control set-up. 

%The information processing capabilities of humans enable people to opportunistically draw and integrate knowledge from nearly any information sources that become available to them.  However, supporting similar, opportunistic integration of digital, structured data from diverse sources remains difficult without tedious, manual integration, due to problems of heterogeneity that arise when data modelled and represented differently are brought together.  In this paper, we investigate the feasibility of minimally extending digital Personal Information Management (PIM) tools to support lightweight, user-driven mixing of previously un-integrated data, towards enabling users to take advantage of the vast emerging ecosystems of structured data being made available.  We conducted an exploratory, sequential, mixed-method investigation, starting with two pre-studies of the data integration needs and challenges, respectively, of Web-based data sources. These observations led to our design of \emph{DataPalette}, an interface that introduced simple co-reference and group multi-path-selection mechanisms for working with terminologically and structurally heterogeneous data.  Our lab study showed that participants understood the interaction mechanisms introduced, and made more carefully-justified decisions during subjective-choice tasks when using DataPalette than when using a control interface, drawing information from more data sources in the process.
% While people naturally draw from diverse information sources in the course of routine decision-making tasks, complementary support for managing heterogeneous data in digital Personal Information Management (PIM) tools remains poor. In this paper, we present an initial investigation of user-driven, ad-hoc data integration approaches for PIM, towards enabling greater use of the emerging ecosystems of structured data on the Web. We conducted an exploratory, sequential, mixed-method investigation, starting with two pre-studies of the data integration needs and challenges, respectively, of Web-based data sources. These observations led to our design of DataPalette, an interface that introduced simple co-reference and group multi-path-selection mechanisms for working with terminologically and structurally heterogeneous data.  Our lab study showed that participants understood the interaction mechanisms introduced, and made more carefully-justified decisions during subjective-choice tasks when using DataPalette than when using a control interface, drawing information from more data sources in the process.

%% While people naturally draw from diverse information sources in the course of routine decision-making, complementary support for managing diverse, heterogeneous data in digital Personal Information Management (PIM) tools remains poor.
%% In this paper, we present an exploratory initial investigation of user-driven, ad-hoc data integration approaches for PIM, towards enabling greater use of emerging ecosystems of structured data available on the Web.
%% We conducted an exploratory, sequential, mixed-method study, starting with two pre-studies focusing on the data integration needs and challenges, respectively, of effectively combining data from diverse Web-based structured data sources.
%% These observations led to our design of DataPalette, an interface that introduced drag-and-drop and path-selection mechanisms for working with terminologically and structurally heterogeneous data.  
%% A lab study showed that users understood the interaction mechanisms introduced, and that DataPalette allowed them to make more carefully-informed decisions, drawing from more data sources while making multidimensional subjective decisions.

% We find that the ``light-touch'' data integration mechanisms introduced allow people to effectively work with and combine information from multiple sources, and more thoroughly justify their choices 
%% exploratory, sequential mixed-method study of 
\end{abstract}

\keywords{Personal information management; end-user data integration; mash-ups; sensemaking with data}

\category{H.5.2.}{Interaction styles}{Direct manipulation}
\category{H.2.5.}{Heterogeneous Databases}{Data translation}
\category{H.5.m.}{Information Interfaces and Presentation}{Miscellaneous}

% \terms{Human Factors; Design; Measurement.}

\section{Introduction}
In recent years, an unprecedented quantity and variety of information has been made available as structured data on the Web.  The explosion of structured data APIs and downloadable data sets has arrived from many different sectors, including retail, banking, social networking, opinion and recommendation sites, mobile and desktop apps, as well as from new kinds of sensors and devices such as wearable activity and bio-sensors. Beyond commercial apps and services, governments have embraced releasing data as a way of providing transparency and accountability to their citizens, causing a huge push to release ``open data'' to the public, at scales ranging from the smallest local councils to entire national departments.  

A common goal for the release of such data has been to provide end-users with the ability to make more informed decisions pertaining to their health, wealth, and well-being \cite{Shadbolt:2006:SWR:1155313.1155373}.  Thus far, however, this data has been predominately used by app developers, journalists and other data specialists in one-off data analyses, apps and investigations.  Hence, as yet, these data still remain far from making a positive impact upon the activities of ordinary people. A core reason for this, we posit, is a lack of suitable tools for accessing and interrogating these heterogeneous data sources, as well as a means by which these disparate information sources can be effectively brought together and cross-referenced.  For example, most personal information management (PIM) tools only provide the capacity to manage small, pre-fixed sets of data types (such as calendar appointments, address book entries,  tools and to-do list items).  Alternatively, they may provide little or no support for structured data, as exhibited in word processors, text editors, and sketching/drawing tools \cite{infoscraps}.   

% We hypothesise that end-users will benefit from tools that allow them to effectively browse, use and consume heterogeneous structured data from diverse sources. 
In this paper, we present an investigation of ways that PIM tools might be extended to allow data to be brought together in an ad-hoc fashion from arbitrary structured data sources, so that end-users can effectively harness knowledge emerging from the vast ecosystems of data.  For this purpose, we have employed an exploratory, mixed-method approach with three sequential stages. First, in a pre-study, we have conducted a series of semi-structured interviews in order to understand the various types of tasks people perform using multiple information sources, and the processes that they rely upon to perform such tasks.  Our results suggest that people typically draw upon multiple, diverse sources for a number of reasons, including increasing the breadth of information, assessing the reliability of information, and gaining multiple perspectives.  

% Second, we conducted a quantitative, structural analysis of various popular personal data sources available today to identify potential barriers to effective unification of data.  Drawing upon definitions from the database integration and automatic schema matching literature, we characterised the types of heterogeneity exhibited across data sources in six domains: address books (contact info), event calendars (events), music (songs/tracks), shopping (product info) social networking (profiles) and weather (forecasts), finding that terminological heterogeneity dominates the simpler data feeds (including social networking and restaurant recommendations), while structural issues pervade the more complex schemas of online retailers' product catalogues.

Second, we have carried out a structural analysis of data records from personal data sources to identify the most common kinds of problems likely to arise from integrating data from these multiple sources.  For this, we have examined data sources from six common domains: contacts, events, music, shopping, social networking and weather. We have discovered, in our analysis, that while terminological heterogeneity is the most common issue for unifying simpler data records (such as address book contacts and social network profiles), structural differences are exhibited among more complex schemas, such as online retailers' product catalogues.

Third, we have developed DataPalette, an interface that enables serendipitous ``data mixing,'' eliminating the need for people to write bespoke code to effectively combine and compare heterogeneous data.  DataPalette facilitates basic integration of diverse, heterogeneous data sources using simple interface gestures.  A usability evaluation of DataPalette has revealed that most users are comfortable with its interactive integration mechanisms, and that it effectively improves people's abilities to perform multi-faceted decision-making tasks using multiple sources.

\section{Background}
Our work has been informed by three fields of inquiry, comprising PIM, database integration, and end-user mashups and toolkits.  Our primary motivation stems from field studies in PIM, where the need for consolidating data has been observed. This is an area in which many challenges remain, specifically, in reconciling the differences that arise among representations when data is created by different people, at different times, and for different purposes. As described by Alon Halevy:

\begin{quote} 
The problem stems from [the fact that] we are trying to integrate data systems that were developed for slightly (or vastly) different business needs. Hence, even if they model overlapping domains, they will model them in different ways. Differing structures are a byproduct of human nature --- people think differently from one another even when faced with the same modelling goal~\cite{halevy2006data}.\looseness=-1
\end{quote}

The benefits to the end-user in conquering data integration have been demonstrated in PIM prototype systems that employ integrative data models.  For example, the uniform query capabilities provided by SEMEX~\cite{semex} and SIS \cite{Dumais:2003:SIS:860435.860451}, show the speed, efficiency and re-findability gained when a user is able to quickly trace and cross-reference information about people, places and things mentioned throughout files, folders, e-mail, and other information repositories.  Similarly, Haystack \cite{haystack} demonstrates that, when a single, consolidated data model is used across applications, the results include increased efficiency, the elimination of information fragmentation, and reduced effort, with the user being able to view and re-use information easily in multiple task contexts. 

Because of the multi-faceted challenges of data integration, contrasting approaches have been investigated in different research communities. In the fields of database integration and the Semantic Web \cite{Shadbolt:2006:SWR:1155313.1155373}, for example, automatic, machine-learning approaches, at either the level of \emph{ontology/schema matching}~\cite{euzenat2004api,doan2003learning}, or \emph{instance matching}~\cite{suchanek2011paris,castano2006matching} have been pursued. In contrast, the end-user programming community has preferred user-driven approaches, in which the user orchestrates the process of reconciliation at various levels of specificity.  Systems that use this approach include ``mash-up makers'' (such as Mashmaker, \cite{intel_mashmaker}, Marmite \cite{Lin:2009:EPM:1502650.1502667}, and Vegemite \cite{Wong:2007:MMM:1240624.1240842}) and visual programming language environments such as Yahoo Pipes \cite{citeulike:8887891}.

DataPalette's approach exhibits similarities with the user-driven methods just mentioned, in that the user performs data reconciliation using concrete instances as examples, but also avoids the need for any sort of programming.  Previous systems utilising this approach have included ``Cards, Relations and Templates'' \cite{Dontcheva:2007:RCS:1294211.1294224} and Potluck \cite{citeulike:3875264} both of which permit the user to reconcile instances from different schemas into a uniform representation using drag-and-drop gestures to specify relations among fields.  DataPalette extends this approach to a data workbench environment which allows people to easily consolidate and compare instances by their properties.

% algorithms that train on a corpus of alignments and produce new alignments on unseen data schemas or instances, respectively

%A result of this problem is that users can experience data fragmentation~\cite{Jones05towardsa} across multiple web-based applications and services, and struggle to consolidate across them~\cite{bergman,boardmansasse}.  In our own previously-conducted field study, \cite{infoscraps} we observed variations of manual ``coping strategies'' (or, if programmers, elaborate, custom-coded one-off solutions) to allow people to manage both online and offline data.  Similar findings from other studies observed volunteers' ``homebrew databases'': manually-maintained information collated to handle the heterogeneous data requirements of groups needing to coordinate their activities~\cite{Voida:2011:HDC:1978942.1979078}.\looseness=-1

%We focus on \emph{instance-level} matching, as schemas may not always be available, or easily accessible to users.\looseness=-1


% Pertaining to each system's ability to integrate information from arbitrary new data sources, however, both systems generally required new sources to either already conform to pre-specified ontologies, or have the user specify such a mapping manually.

% i think we do not need to differentiate between semantic web and database integration here, we're saying they're both bad, let's lump them together to keep the argument flowing and not kill our readers


%In this section, we motivate our work using three fields: PIM, data integration, and end-user mashups and toolkits.  Our primary motivation stems from field studies in PIM, where consolidating and working with data from multiple sources has remained a challenge for over a decade. Recently however, users are experiencing data fragmentation~\cite{Jones05towardsa} across multiple web-based applications and services, and struggle to consolidate across them~\cite{bergman,boardmansasse}.  In our own previously-conducted field study, (reference anonymised) we observed variations of manual ``coping strategies'' (or, if programmers, elaborate, custom-coded one-off solutions) to allow people to manage both online and offline data.  Similar findings from other studies include Voida et al.'s observations of volunteer coordinators' ``homebrew databases'', manually-maintained information assemblages concocted to handle the widely varied and heterogeneous data collection requirements such groups needed to coordinate their activities \cite{Voida:2011:HDC:1978942.1979078}.
%% TODO MORE HERE

%% don't like the beginning of this > 
%Enabling PIM tools to supporting ad-hoc data integration has remained difficult because of the complex, theoretically difficult nature of data heterogeneity; specifically, reconciling the differences that arise among representations when data is created by different people, at different times, for different purposes. As described by Alon Halvey:

%\begin{quote} 
  %The problem stems from the fact that] we are trying to integrate data systems that were developed for slightly (or vastly) different business needs. Hence, even if they model overlapping domains, they will model them in different ways. Differing structures are a byproduct of human nature --- people think differently from one another even when faced with the same modelling goal. \cite{alonhalevy}
%\end{quote}


% A different approach entirely has been taken in the web mash-up community; this community has largely focused on end-user interfaces that allow people to interactively reconcile data from multiple sources.  Yahoo Pipes! is a visual programming language aimed at letting novice programmers easily create data-transformation workflows, but remained rather challenging to  use and effort-intensive for one-off information tasks.  Mash-up makers such as Intel Mashmaker \cite{intel_mashmaker}, QDEWiki \cite{}, and TX2 \cite{}. DataPalette's approach is most directly inspired by ``lightweight'' visual, user-interactive data collection, consolidation and alignment tools such as Potluck \cite{citeulike:3875264} and Cards \cite{Dontcheva:2007:RCS:1294211.1294224}.

% Semi-automatic approaches use varying levels of support to aid a user, from prompting users to manually check flagged alignments, to suggesting possible alignments.  Allowing users to compare instances across heterogeneous data is powerful because users can combine and evaluate multiple sources.  In principle, automatic instance matching approaches would allow users to seamlessly browse this data, however for now and the foreseeable future such approaches cannot make use of personal knowledge and do not guarantee their alignments.  Therefore, in our work, we adopt a semi-automated matching approach, which will support the user to make alignments between web data and their personal data.


% integrated into the above :: 

%% The Semantic Web research community has approached the problem of data integration in terms of \emph{ontology matching}, which can be split into two distinct strategies: \emph{schema} and \emph{instance} matching.  Instance matching differs from schema level matching in that it aims to detect instances referring to the same real world object, while schema matching aims to find a set of mappings between concepts and properties in different ontologies. For our purposes of allowing users to explore and compare data from different websites, we are particularly interested in aligning instances of the most common forms of data that people compare from website to website.  
%% Instance matching within this scope is in its infancy, some of its problems have been addressed by the record linkage problem in the database field \cite{fellegi1969theory,winkler1999state,gu2003record}.  However, there are new problems to address in this field, which are strongly related to schema matching, including structural heterogeneity and logical heterogeneity. The approaches used to match instances typically use: natural language processing, using lexicons like Wordnet\footnote{\emph{Wordnet} - \url{http://wordnet.princeton.edu}} to identify synonyms, and word stems \cite{euzenat2004api}; machine learning techniques \cite{doan2003learning}; probabilistic approaches \cite{suchanek2011paris} and comparisons of instance schemas structural and logical definitions \cite{castano2006matching}.  In our case, this is problematic because information from the web does not always have a schema.  In real-world scenarios, semi-automatic ontology matching approaches are favoured over automatic because reconciling the differences between ontologies that were designed for different purposes is not always accurate.  Semi-automatic approaches use varying levels of support to aid a user, from prompting users to manually check flagged alignments, to suggesting possible alignments.  Allowing users to compare instances across heterogeneous data is powerful because users can combine and evaluate multiple sources.  In principle, automatic instance matching approaches would allow users to seamlessly browse this data, however for now and the foreseeable future such approaches cannot make use of personal knowledge and do not guarantee their alignments.  Therefore, in our work, we adopt a semi-automated matching approach, which will support the user to make alignments between web data and their personal data.
%% The Semantic Web community use ontologies to formally describe vocabularies for specific domains by defining axioms describing entities, instances of entities and the relationships that hold among them \cite{borst1997construction}. The axioms in an ontology can be either assertional or terminological, the former describes the schema of the entities and the latter the instances of those entities. Typically, these ontologies are marked up using OWL (Web Ontology Language) and Resource Description Framework Schema (RDF(S)).  There has been an explosion of ontologies published online, many of which describe the same entities.  These entities may or may not share the same entity names or properties.  Therefore using data from heterogeneous ontologies can be difficult. The field of ontology matching can be split into two fields: schema and instance matching.  Instance matching differs from schema level matching, because it aims to detect instances referring to the same real world object, while schema matching aims to find a set of mappings between concepts and properties in different ontologies.
% For our purposes of allowing users to explore and compare data from different websites, we are particularly interested in aligning instances of the most common forms of data that people compare from website to website.  Instance matching within this scope is in its infancy, some of its problems have been addressed by the record linkage problem in the database field \cite{fellegi1969theory,winkler1999state,gu2003record}.  However, there are new problems to address in this field, which are strongly related to schema matching, including structural heterogeneity and logical heterogeneity.
% The approaches used to match instances typically use: natural language processing, using lexicons like Wordnet to identify synonyms, and word stems \cite{euzenat2004api}; machine learning techniques \cite{doan2003learning}; probabilistic approaches \cite{suchanek2011paris} and comparisons of instance schemas structural and logical definitions \cite{castano2006matching}.  In our case, this is problematic because information from the web does not always have a schema.  In real-world scenarios, semi-automatic ontology matching approaches are favoured over automatic because reconciling the differences between ontologies that were designed for different purposes is not always accurate.  Semi-automatic approaches use varying levels of support to aid a user, from prompting users to manually check flagged alignments, to suggesting possible alignments.  Allowing users to compare instances across heterogeneous data is powerful because users can combine and evaluate multiple sources.  In principle, automatic instance matching approaches would allow users to seamlessly browse this data, however for now and the foreseeable future such approaches cannot make use of personal knowledge and do not guarantee their alignments.  Therefore, in our work, we adopt a semi-automated matching approach, which will support the user to make alignments between web data and their personal data.

\section{Pre-studies: Identifying Needs and Challenges}
%% not sure where this goes >> but i want to keep it

In the first pre-study, we aimed to get an updated understanding of the use of multiple information sources in information gathering on the Web. Several basic questions drove our inquiry.  First, were people increasingly relying only on a handful of ``super-sites'' (Facebook, Wikipedia), or searching across distributed sources of information?  If the former were true, merely integrating PIM tools with the small number of super-sites would provide greater benefit than tackling the more challenging problem of integrating data from an array of arbitrary sources on the Web.  In a related vein, why did some people choose a single source for information gathering, while others selected multiple sources?  What advantages were gained in consulting multiple sources? 

% If they did what kinds of tasks did people required diverse information collection and were these kinds of tasks rare?  If so, this would suggest that perhaps specialised interfaces could be concocted for this purpose rather than it being a PIM need. 

The second pre-study focused on the characteristics of the data available from the selected sites. The purpose of this exercise was not to identify specific characteristics of particular sites, but to establish general characteristics across a variety of domains, so that typical integration problems that might arise when mixing these data could be identified.  In the next two sections, we present our methodologies and the results of our pre-studies.

\subsection{PS.1 - Understanding Data Diversity in Everyday Tasks}
% Rewritten with paragraph below; feel free to revert, or delete this if you're happy, or whatever.
% We designed a semi-structured interview about tasks people performed online that required the use of multiple websites, and the processes people used to perform such tasks.  We analysed the data collected from this study using a thematic approach.  In our first pre-study, we investigated the types of tasks people performed online that required heterogeneous data sources, and which tools they would use to organise a social event involving around 15 people.  We planned to interview 8 participants, using a general interview guide approach based on a set of questions.  This approach allowed the interviewer to adapt the interview to the participant's experiences, while collecting the same general areas of information.  Each interview was recorded and notes taken, the interviewer was trained in the purpose of the study and to minimise bias.

In the first pre-study, we held semi-structured interviews to better understand the reasons that people drew information from single or diverse information sources. We interviewed 8 participants, asking them to identify tasks they had performed recently, which had required the use of multiple information sources.  This was followed by determining the kinds of sources which were used, and the tools that were needed to manage the resulting information.  We then inquired how each participant would go about planning a hypothetical social event entailing details such as scheduling a  date, finding a suitable location and selecting the appropriate entertainment.

\subsubsection{Results - Heterogeneous Data Tasks}

The 8 participants, recruited informally via word of mouth, consisted of 7 males and 1 female, ranging in ages of 18--32.   
% mention # that were computer scientists here?

%\subsubsection{Question 1: Heterogenous Data Tasks}
All participants reported regular usage of multiple websites to accomplish tasks, examples of which included: shopping, choosing a restaurant, job-seeking, selecting a university, seeking a recipe, or finding answers to technical problems.  When initiating a task, it was common for participants to use Google to discover several related websites, which would then be explored in different ways, depending on the task at hand. For shopping-oriented tasks, a balance of price, quality of merchandise, and speed of delivery was sought.  For product reviews, single sources alone were not trusted due to possible biases, or incomplete coverage of products' desired features.  
% Jim - Not sure if this is relevant. If it is, put it back in.
% one participant said that video reviews of items were particularly helpful, as the aesthetics and scale of the item could be seen.
% Social networks were identified to have different functions, such as different groups of people belong to each and share different types of opinions.  One participant said that they shared their outlook and gmail calendars, but only for work events and did not record social activities on them.
To benefit from the fullest coverage of information, many different websites of different types were consulted, such as manufacturers' websites for technical details, and review aggregates for a range of opinions.

%\subsubsection{Question 2: Process Used to Organise a Large Social Event}

In response to our question of how participants would plan a large social event, most stated they would first confer with friends to get their ideas, preferences and recommendations.  Then, they would select the venue, locations, restaurants and activities through a number of sources: their own prior experience, friends' recommendations, searching Google maps, and dedicated reviews sites (such as Yelp for restaurants).  The participants cited the cost and ease of accessing a location as the most important factors when choosing the venue. 
% They considered how to get there and looked up train or bus times on the Web, or organised carpools.  
%When organising an event, the weather was not that important because they did not trust the accuracy of predictions.  Also, friends' preferences in price and food choices were not seen as a priority; they would try to be inclusive but only if it meant small changes to the plan.  Choosing food and timings were often made on-the-fly, by either with the use of mobile applications or by walking past a location.

% old:
% Participants said they would organise a large social event by first conferring with friends about their ideas, preferences and recommendations.  They selected venues, locations, restaurants and activities through a number of sources: their own prior experience, friends' recommendations, searching Google maps, dedicated reviews sites (such as Yelp for restaurants), and through web search.  People stated that the cost, price and easy to get to locations were the most important factors when choosing a venue.  They considered how to get there and looked up train or bus times on the Web, or organised carpools.  When organising an event, the weather was not that important because they did not trust the accuracy of predictions.  Also, friends' preferences in price and food choices were not seen as a priority; they would try to be inclusive but only if it meant small changes to the plan.  Choosing food and timings were often made on-the-fly, by either with the use of mobile applications or by walking past a location.\looseness=-1


%% Most people felt that being assertive and posting their decisions about the date and time on Facebook meant that organising events were more successful than trying to gather a consensus.  They expected that their friends would voice any objections if they could not attend or like the restaurant or activity selected.   They selected venues, locations, restaurants and activities based on their own knowledge, friend's recommendations, Google maps, reviews obtained through web search and sites such as TripAdvisor.  People stated that the cost, price and easy to get to locations were the most important factors when choosing a venue.  They considered how to get there and looked up train or bus times on the Web, or organised carpools.  When organising an event the weather was not that important because they did not trust the accuracy of predictions.  Also, their friend's preferences in price and food choices were not a priority; they would try to be inclusive but only if it meant small changes to the plan.  Choosing food and timings were often made on-the-fly, by either with the use of mobile applications or by walking past a location.
% previous
% All of the participants would organise a large social event by first conferring with friends about their ideas, preferences and recommendations.  The medium they would use included face-to-face, phone calls, email, Skype, Facebook events, depending on the time scale required to organise an event in general if there was a short time scale people would speak in person or on the phone.  Otherwise, people would set up a Facebook event page to discuss ideas with their friends.  If their friends were not on Facebook they would email them.  All but one participant said they would not use Doodle\footnote{Doodle - \emph{www.doodle.com}} to the organise day and time of an event, because they felt that people did not fill in the form and it was more suit to organising work events.  

%% Most people felt that being assertive and posting their decisions about the date and time on Facebook meant that organising events were more successful than trying to gather a consensus.  They expected that their friends would voice any objections if they could not attend or like the restaurant or activity selected.   They selected venues, locations, restaurants and activities based on their own knowledge, friend's recommendations, Google maps, reviews obtained through web search and sites such as TripAdvisor.  People stated that the cost, price and easy to get to locations were the most important factors when choosing a venue.  They considered how to get there and looked up train or bus times on the Web, or organised carpools.  When organising an event the weather was not that important because they did not trust the accuracy of predictions.  Also, their friend's preferences in price and food choices were not a priority; they would try to be inclusive but only if it meant small changes to the plan.  Choosing food and timings were often made on-the-fly, by either with the use of mobile applications or by walking past a location.

\subsubsection{Summary of Findings}

All of the participants used multiple websites in order to complete their tasks, and all felt that the lack of existing integration between sites hindered their ability to make informed choices. Participants prioritised the sources they used by both the ease and immediacy of accessing them.  As a result, sources that took much effort or time to investigate were often excluded.

% details of their decision making process were excluded because participants felt it was too much effort to investigate them. % Participants felt that they did not include particular aspects of a decision because the process to investigate them would be too difficult or take too much time. 

%People said that they would like a website that could support the evolution of an event, that allowed them to post drafts of an event.  They felt that organising an event should be a process that changes over time.  Three participants said that they would like a recommendation system for places to eat and activities.  Another strong requirement was that it had to be ubiquitous so that everyone could use it because they wanted a single place to communicate with their friends.  While Facebook was the most popular social networking site for organising events, half of the participants felt that it was not the best solution and would prefer a collaborative environment.

\subsection{PS.2 - Technical Challenges of Data Integration}
For Pre-Study 2, our analysis of structured data feeds started with identifying a set of candidate sources to examine.  We consulted the ProgrammableWeb API directory\footnote{ProgrammableWeb: \url{http://www.programmableweb.com/apis/directory}} list of most popular data feeds for this purpose.  To examine the many varieties of personal data sources, we selected from 5 categories: social network services, retailers, online event calendars, music sites, and weather, selecting 2--5 sources from each, for a total of 20.  

For each source, 3--5 typical records of a particular type were obtained from each service's API or feed.  For social networking sites, user profiles were the type of record examined, while for retail sites, it was product information; for event tracking sites, we focused on event time/date information; for music sites, on song listing information; and for weather sites, forecast records were selected for our study.
%Records were located either by first querying for popular key terms using each site's keyword query API (if available), or a ``top products'' query if available.  
For each such data record, two complexity metrics were computed: the \emph{average width}, corresponding to the number of properties, and the \emph{average depth}, corresponding to the number of nested structures.  In addition, a third metric measured degree of overlap among the sources in each category.  This was accomplished by first mapping \emph{equivalent properties} between schemas, performed manually by creating alignment tables for all properties of data sources in each category.  Each row comprised a property of a record of one data source, and all its closest matching properties from the others.  We used both property names and attribute descriptions (in documentation, if available) to determine which properties were semantically equivalent.

%Determining the width required first finding the appropriate level for comparison; for example, for Amazon's retail product ``Item'' records, the sub-structure under the ``ItemAttributes'' property was used instead of the root-level record. The average depth was simply the mean depth to each leaf node from the chosen comparison level.
% This step was done manually, with an effort to select most similar components for comparison.  
% Depth was computed as the average number of levels from record root to leaves across all properties, and was measured, with width, to convey the overall size/complexity of each record.

Once established, equivalent properties were examined, first, for naming inconsistencies.  Then, disregarding names, we examined whether the property's values were structurally compatible.  That is, if both values consisted of the same literal data type, or had one or more equivalent subfields, they were considered compatible.  Finally, we examined incompatibilities not covered by either naming or structural differences alone.  These \emph{modelling differences} arose from a variety of reasons, including, but not limited to, measurement unit inconsistencies, measurement method disagreements (e.g., ``dew point'' versus ``relative humidity''), differences in scale and granularity, and mismatches in what was being modelled (e.g., ``offer'' versus ``listing'').\looseness=-1

\subsubsection{Results}
While most of the data records examined in PS.2 were small and relatively simple, nearly one in each category was substantially larger and more complex. In particular, Amazon, Soundcloud, Twitter and Weather Underground were the most complex in each of their respective categories. Mapping equivalent properties among the instance records for each category revealed little overall overlap, except among the smallest records (which had few properties to begin with).  This finding suggests that consolidating such records would substantially increase the amount of information held by each.  Some of the unique properties were primarily for internal use (such as service-specific IDs).  Some, however, contained useful properties which were simply absent in alternate sources.  For example, among the 4 music data providers examined, only Spotify listed the source album that featured a particular song.  Such omissions revealed that data APIs often were reflective of each provider's own specific needs, necessitating the integration of information across multiple sources to create more complete and useful representations.

A second observation in PS.2 was that equivalent properties were only rarely given the same name. Thus, terminological (or naming) heterogeneity was prevalent across nearly all records observed.  Structural inconsistencies were rarer, with the most common case occurring where a record that represented a value as a simple literal was expanded out in another as an entire sub-structure.  This most commonly occurred for fields with common string serialisations, such as dates, prices, and intervals.  Meanwhile, examples of modelling differences were even rarer than those of structural heterogeneity, with the few we found mostly being attributed to concepts from one source not mapping perfectly to those of another source, for example, due to differences in methods of measurement, or measurement units.
% We also encountered two examples of records in which multiple data fields were nested as a single literal, textual ``description'' field.  This behaviour stems from the intended use of such records only by human readers, rather than in structured data applications.  

To examine value consistency, we compared source schemas provided in the API and feed documentation of the data providers.  There was substantial terminological inconsistency among the value names for enumerated types, with exact matches occurring less than 10\% of examined value pairs.  There were also range inconsistencies, corresponding to cases where values represented in one record were not represented as valid values in the range of the equivalent property in the target schema.  A simple example of this was the ``gender'' property  on Facebook, which allowed only ``male'' and ``female'' values, while Google+ included a third option,``other''.  

In summary, we found in our PS.2, that while data records ranged in complexity, no single source subsumed any others; all contained unique properties.  Moreover, the most common types of heterogeneity exhibited were terminological and value-related, which occurred vastly more often than structural or modelling issues.

%\section{Designing the DataPalette Interface}
\section{DataPalette : An Interface for Data Mixing}

\begin{figure*}[thb]
\begin{center}
\includegraphics[width=18cm]{img/screenshot}
\caption{DataPalette Workspace, a file manager-inspired Drag and Drop interface for structured data mixing. Collapsible displays of data sources are listed on the left, from which instances or entire sets of items can be dragged to form a window (group) on the workspace.}
\label{fig:workspace}
\end{center}
\end{figure*}

The primary goal of DataPalette (henceforth DP) was to empower end-users so that they were able to mix arbitrary, structured data feeds on-the-fly, while solving particular information task(s) more effectively.  Unlike mashup makers, such as Yahoo Pipes!, the aim was to facilitate such integration without the need for a separate step involving programming, scraping, shaping, mapping or integration. 

% Instead, DataPalette's approach is most directly inspired by ``lightweight'' visual, user-interactive data collection, consolidation and alignment tools such as Potluck \cite{citeulike:3875264} and Cards \cite{Dontcheva:2007:RCS:1294211.1294224}.

The two pre-studies above provided valuable insights towards this goal, which, in turn, informed our design process. PS.1 confirmed the need for data integration, by showing that people preferred to rely upon multiple sources of information for making important decisions; PS.1 also identified the kinds of sources most commonly used.  PS.2, meanwhile, revealed that the most common kinds of heterogeneity across data sources were of the terminological or structural varieties. As these were the ``simpler'' kinds of heterogeneity, this gave us optimism that an interaction-based approach would be feasible.  

In the following sections, we describe the design process of creating the prototype of DP.  This is followed by detailed descriptions of the prototype, with justifications grounded in the pre-studies.

\subsection{Design Process}
We followed a five-phase spiral model, consisting of planning, designing, mocking-up, prototyping, and testing, to derive the final design of DP.  This multi-phase process was used, due to the high degree of initial uncertainty associated with how users would achieve effective data mixing. We approached this design challenge through alternative generation and elimination; alternatives were designed, drawn up and evaluated by colleagues (and in later iterations, non-expert potential users), who critiqued the alternatives. The ease with which designs could be prototyped in HTML5 with modern web frameworks allowed us to perform this process of develop-test-iterate rapidly through seven iterations.

In order to allow new users to be comfortable with our interface, we adopted the look and feel from OS X Finder-style file managers.  In the DP workspace, shown in Figure \ref{fig:workspace}, the user would be able to freely drag and drop entities from data sources (on the left) into windows that they have created, resized, arranged and labeled. Unlike file managers, the basic unit of data was not a file, but an \emph{instance} --- corresponding to a single data record, JSON object, RDF instance, or any small bit of structured data. In order to make working with relational graphs manageable, an early decision we made was to break up RDF-like relational data into discrete instances with properties. This was done at time of import, and could be done for every major Web data feed type (JSON, XML, RDF) without any loss of generality.

\subsubsection{Multi-path selection: link-sliding for heterogeneous sets}
Typically, users are interested in viewing and comparing the \emph{properties} of instances; for example, a user might be keen to examine a product's price, rating, manufacturer and so on.  To support such comparisons, an instance's properties would be displayed beneath it; selecting a property would create a \emph{path selection}, which would dereference all of the instances in a group that contained the selected property and displayed their corresponding values.  For example, when a user selected the \emph{manufacturer} property for a product, all products in the same group with a manufacturer property would be dereferenced, causing the manufacturers to be displayed alongside their corresponding products.  When such a path selection was applied, the properties displayed were updated to be the set of properties of the \emph{terminating value of the path}, so that this value could be dereferenced further.  Having selected a manufacturer, a user might want to be informed of its reputation.  By selecting the ``reputation score'' property, the previous path selection would then be extended. This process is illustrated in Figure \ref{fig:multipathing}.

\begin{figure}[h]
\begin{center}
\includegraphics[width=8.7cm]{img/multipathing}
\caption{To see properties, users click on the name of the property. When instances do not have a particular property, additional property names can be added.}
\label{fig:multipathing}
\end{center}
\end{figure}

When instances could not be dereferenced by the chosen path selection, an additional path selection could be created. As with the first path selection, this would cause all matching instances to be dereferenced.  Each group would be able to carry an arbitrary number of path selections, and each path selection could be extended continually by selecting successive properties of values. This would achieve the ability to \emph{link slide} multiple instances simultaneously, as introduced by Parallax~\cite{parallax}, extended to support sets of heterogeneous items through multiple parallel simultaneous paths.  Multiple-path group-dereferencing would result in two key benefits. First, users would be able to quickly compare all instances that have the same structure, and second, instances with different property names would be easily consolidated.

%
%\begin{enumerate}
%\item Clicking on a property dereferences all corresponding values makes it easy to quickly compare all instances that have the same structure.  Although we were concerned that users might be surprised that path selection applied to all objects within each group in parallel, users adapted very quickly and used this functionality to save them time.   
%
%\item Supporting dereferencing along different paths \emph{by structure} allows instances with different property names, and even sub-structures to be quickly consolidated by separate dereferencing, thereby effectively coping with terminological and structural heterogeneity.
%\end{enumerate}
%
\subsubsection{Coreference consolidation: Drag-and-Drop Same-as}
A major challenge with integration from multiple sources is coreference consolidation, or combining into one, representations that co-refer to the same entity.  For example, when consolidating one's friends from Facebook, Google+, and LinkedIn, one might wish to eliminate duplication and combine friends' profiles across multiple services.  Although we considered ways to do this automatically, PS.2 revealed no viable method to reliably identify the co-referring instances; due to a lack of standard URIs across social networks, identifiers used by each network were system-specific and inconsistent. Thus, we sought to instead make it user-driven, and easy to perform manually.  

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=8.7cm]{img/sameas}
\caption{\emph{Coreference consolidation with drag-and-drop Same-As} - When two instances represent the same entity, users can drag one on top of the other, and they are combined - effectively displaying the union of properties of both source entities. This can be un-done by deleting the Same-As relationship in the view in the lower-left corner of the workspace.}
\label{fig:sameas}
\end{center}
\end{figure}

To remain consistent with the drag-and-drop interactions used throughout the interface, we introduced the ability to simply drag one instance directly on top of another, to specify that these two items should be combined.  This action also caused the \emph{Same-As display} in the lower left of the screen to indicate this new combined relationship.  The display also acted as a mechanism to delete/undo combinations, which reverted representations of instances back to their original, separate forms. An illustration of this interaction is provided in Figure \ref{fig:sameas}.  Since individually dragging and dropping items could be tedious for large groups of items, we extended this to allow entire groups to be dropped on to other groups.  DP would then identify matching pairs among items in the dragged and target groups by comparing the labels of items in each group, respectively.  Only exact matches (excepting white space and underscores) were considered to correspond to label matches, and these were automatically combined.  The rest were added to the target group as distinct elements, which could be manually combined by hand.\looseness=-1

%We are considering more sophisticated / less fragile approaches to matching in the future, which would make the system assistive. By making consolidation user-driven, we gave users freedom to combine things when it suited them. As we saw in the system evaluation, while in certain circumstances users preferred combining representations, in others people preferred not to.  Thus, user-initiated consolidation afforded an additional flexibility that was ultimately deemed beneficial.

\subsubsection{Enumerated-type value consolidation}
PS.2 revealed that enumerated values of properties were often inconsistent, e.g., ``Casual dining'' vs ``Relaxed'' for a restaurant's ``atmosphere'' property. To reconcile and consolidate corresponding values from different  data sources, we extended the drag and drop support of co-reference combination to also allow users to drag and drop to combine enumerated literal values as well.  

\subsubsection{``Do What I Mean'' Visualisation}

To make it easier for people to visually compare aspects of instances, we created a charting tool and mapping feature.  To ensure that these tools were suitable for rapid utilisation, (e.g., data exploration), they were designed to automatically configure display parameters based on the instances or groups that were dropped onto them. In the current prototype, this ``Do What I Mean'' behaviour automatically would set whether the plot was a histogram representation (counts of values) or a numeric value display, based upon the types of the dereferenced values being plotted.  Hence, non-numeric values would be shown on a histogram, while numeric values were displayed as a bar or line chart.  Similarly, the map was made to detect address strings and latitude/longitude pairs, geocoding them where appropriate, and determining the optimal bounding box to display all items at maximum zoom.

\subsubsection{Model-based brushing}
To avoid the confusion of having a single instance represented across several groups, we provided \emph{universal brushing} across the interface.  Hovering over any representation of any instance (an instance block, a map marker or a histogram bar), would cause all other visible representations of that instance to lightly glow, enabling the user to instantly identify all the places that a single instance was represented.

% Data sources were represented as collapsible panels in a sidebar on the left of the workspace, from which instances or entire data sources could be ``pulled off'' onto the workspace.  Figure \ref{fig:workspace} displays the entire UI overview.

%% it would be nice if we had space to summarise but i fear we don't

%% \subsection{Summary of interaction capabilities}
%% \begin{itemize}
%% \item \emph{Group multi-path value selection} - Selecting any of the %% properties of an instance in a group (window) causes all of the rest %% of the instances that have that property in that group to be %% dereferenced along the same property, displaying the resulting value %% underneath the instance label.  Selecting a further property of the %% resulting value further dereferences this value.
%% \item \emph{Drag-and-drop coreference / value combination} - In order %% to specify that two instances correspond to the same entity, they can %% be simply dragged together
%% \item \emph{Group-based Drag-and-drop matching} - In order to specify %% that two instances correspond to the same entity, they can be simply %% dragged together
%% \item \emph{Universal model-based brushing} -
%% \end{itemize}

\section{Evaluation}

In order to determine whether or not the interaction affordances introduced in DP allowed users to perform serendipitous data mixing on real data sources, we devised a within-subjects controlled lab study, which we describe next.

\subsection{Methodology}

We began with three hypotheses pertaining to people's ability to use DP, and its impact on task performance:
%These hypothesis pertain to the usability of DP by end-users (h1), whether DP achieves its stated goal of enabling end-users to integrate data (h2), and finally if it has an effect on task performance (h3) - either in how well people perform a task, how quickly they perform it, or if it reduces task effort, as follows:


% heather: instead of these low-level hypotheses, I've made higher level ones that we can explicitly address in the discussion section - the more hypotheses we have, the more we have to come back to them; since we're short on space we might as well keep it simple!

%% Interaction-method specific hypotheses
%% \begin{itemize}
%% 	\item h1.1 - Do people understanding the problem of %% co-reference, and the need to reconcile coreference problems?
%% 	\item h1.2. Does the ability to do drag + drop combination for %% co-reference reconciliation effectively solve this problem?
%% 	\item h2.1- Do people understand the problem of structural %% differences in data?
%% 	\item h2.2 - Does multipath selection let people effectively %% deal with this -- and work with collections of heterogeneous items?
%% \end{itemize}
%% Are these interaction methods sufficient to perform common tasks %% involving heterogeneous data sources?  Does supporting these simple %% techniques facilitate task completion?

\begin{description}
\item [h1. Usability -] People understand how to use DP.
\item [h2. Data Integration -] People can effectively mix heterogeneous data with DP.
\item [h3. Task completion -] Use of DP improves people's ability to perform the task.
\end{description}

\subsubsection{Study and task design}
To test these hypotheses, we designed a within-subjects (repeated measures) controlled lab study in which participants were asked to perform predefined subjective-choice tasks in two separate timed trials, once with the DP interface (condition A) and once with a baseline interface (condition B).  Each task was paired with one of two datasets, depending on condition, which were counterbalanced in a full-factorial design to eliminate potential ordering, task, and dataset biases.\looseness=-1

The participants were seated at a standard OS X desktop equipped with a 22-inch monitor with a standard keyboard and mouse. Each participant was given a maximum of 10 minutes to complete each of two tasks, but were told that if they finished early, they could inform us and move on to the next condition.  Prior to the A condition trials, participants were trained on how to use DP using a five-minute instructional video.

In the control (B) condition trials, participants were given a web browser with tabs open to all of the data sources they were provided for use, as well as a spreadsheet containing the data taken from websites pertaining to the candidates they were asked to choose from. Participants were told they were free to use the websites and spreadsheets however they wished. 

% why? why were these tasks selected? can we drop in the phrase ``multi-dimensional subjective choice task'' and refer back to PS.1 to justify the choice of tasks?

We established that our two tasks would entail choosing a university and selecting a restaurant for a large social event.  These tasks were selected because in PS.1, the majority of people stated that they had used multiple websites for such tasks.  We introduced a dependent \emph{dataset} variable for each task.  For the University selection task, this variable corresponded to the course for which to select a University, between history and sports science, and corresponding university candidates for each course.  For the restaurant selection task, the variable corresponded to the city and respective restaurants located therein; for this experiment, Glasgow and Cambridge were chosen because they were geographically distant from participants, and would therefore minimise prior familiarity.  

For each of the two tasks, the final candidates from which participants made their selection were pre-selected by us.  For the university task, the six top-ranked universities for each subject according to The Complete University Guide were selected as candidates.  We selected six in order to limit the difficulty of the task given the fixed time allocated for each trial.  In addition, for each course, we provided participants with the profile of a hypothetical student applying to the course, for whom they should base their choice.  This profile included the student's entrance admissions tests scores (corresponding to A/AS-levels), location of the student's hometown, and personal preferences pertaining to how far they wanted to be from home, tuition they could afford, gender balance, and social-athletic-academic balance.

For the restaurant task, we selected six restaurants at random from Yelp's list of popular eateries for each of the two cities.  In addition, for each of the two cities, we generated 12 social network profiles for hypothetical friends who lived in either city, to accompany the participant to the restaurant.  Each friend's profile expressed their street address and preference for favourite cuisine type which could be taken into consideration by participants during the venue selection process. 

For the B conditions, we prepared a spreadsheet listing key statistics for each of the relevant candidates (e.g., universities or restaurants) using data from of a pre-selected set of 6 popular data sources (university and restaurant guides), and collated them into Excel spreadsheets.  

% We established that our two tasks would entail choosing a university and selecting a restaurant for a large social event.  These tasks were selected because in PS.1, the majority of people stated that they had used multiple websites for such tasks.  We used two different variables for each task.  where the restaurant was located (Glasgow and Cambridge) and which subject people chose (sport science and history).  For the restaurant task, the cities Glasgow and Cambridge were chosen because they were geographically distant to participants, and would therefore minimise likelihood of prior familiarity with the restaurants or location.  For the University selection task, two university courses were selected at random from the complete university guide\footnote{The Complete University Guide:\\\url{www.thecompleteuniversityguide.co.uk}}, and the six top-ranked universities for each subject were selected as candidates.  We selected six because it enables us to scope our study, we found through two pilot studies that six data sources provided a sufficient challenge for users to explore the data and required them to use DP's main features. We manually collected the key data points from the websites for use in DP and into Excel spreadsheets (which 40\% of the participants in PS.1 said that had previously used to compare data).

%% \begin{table}[htbp]
%% \begin{center}
%% \small
%% \begin{tabular}{|p{3cm}|p{4.7cm}|}
%% \hline
%% Task	 & Data Sources\\
%% \hline
%% Three universities they would apply to study 1)~Sport Science, and 2)~History & www.thecompleteuniversityguide.co.uk, www.ucas.ac.uk, unistats.direct.gov.uk, www.timeshighereducation.co.uk/world-university-rankings\\
%% \hline
%% Restaurant they would book for 12 friends in 3)~Cambridge, and 4)~Glasgow & www.yelp.co.uk, www.tripadvisor.co.uk, ratings.food.gov.uk, facebook and google plus.\\
%% \hline
%% \end{tabular}
%% \end{center}
%% \caption{For each type of task we used two variables, which affected which data we used from the relevant data sources.} \label{tab:studyfactors}
%% \normalsize
%% \end{table}

\subsection{Data Collection and Analysis}
Each study was overseen by a facilitator and an observer: the role of the facilitator was to explain the study's protocols to the participant and to answer any questions; the role of the observer was to monitor the study and record observations.  Both the facilitator and observer were trained on the purpose of the study, their respective roles, and how they could or couldn't influence the study.   Explicitly, the facilitator and the observer were trained to identify processes that participants might use during a task, so that they could thematically categorise them.  Initially, we identified the following themes: organisation of data, eliminating candidates, co-referencing, and visualisations. The studies were conducted over a period of 4 days.  At the end of each day, the facilitators and observers met to discuss the studies' data and to revisit protocols, if necessary.  During the lab study, we recorded the audio and the participant's actions on screen. We asked the participants to follow a \emph{think-aloud} protocol as they worked, so that we could understand the reasoning behind their actions.  At the end of the study, the participant completed a short exit survey.

After the studies were complete, we generated transcripts of comments made by participants during the think-aloud protocols. At the same time, we created a spreadsheet summarising quantitative metrics pertaining to how much of the various features of DP were used.  After the transcriptions were completed, we categorised comments made by the participants during the study, together with suggestions from their exit survey, and clustered them to common themes.

%% We planned to analyse the qualitative and quantitative data using thematic and statistic analysis, respectively.  In order to carry out our data analysis, we used the recorded transcripts to populate a spreadsheet summarising the quantitative metrics (see Table \ref{tbl:data} for specific fields).  In our study, we aimed to identify process and strategies people used to complete their tasks, so that we could evaluate the effectiveness of DP's interface when aligning heterogeneous data for organisational tasks.  We also categorised people's views voiced during the study and in their exit survey pertaining to DP's usability and interface, and clustered them to evaluate common feedback.

\subsection{Participant Recruitment}

We recruited participants through adverts posted near the Southampton University campus and via e-mails to student mailing lists.  We screened participants to ensure they were at least 18 years of age, but did not filter candidates based on any other criteria.  We received 26 responses to our call, from which we accepted the first 20 applicants (10 of whom were female). Seven were non-students, comprised of university staff and alumni; the remainder were students, 8 studying computer science, and 5 studying other subjects.  Due to the large population of international students and staff at our university, we ended up with a large sample (12) of non-native English speakers; however, since all had passed requisite proficiency tests, we did not think this would substantially impact the results.  On average, each study took 40 minutes to complete, after which participants were offered a small gift certificate from an online retailer for their time. 

%\subsection{Data Analysis} 

%% TODO - emax doesn't like this paragraph - kill it? 
%During the data collection we collated a spreadsheet summarising the participant's gender, typical daily computer usage, the tasks allocated and basic actions performed during the task.  After we had collected the study's data, we performed our data analysis. 

%% TODO look further into types of data analysis....

%\newpage
\section{Results}

% We received 26 responses to our call, from which we selected the first 20 (ten of whom were female). Seven were non-students, comprised of university staff and alumni; the remainder were students, 8 studying computer science, and 5 studying other subjects.  Due to the large population of international students and staff at our university, we ended up with a large sample (12) of non-native English speakers; however, since all had passed requisite proficiency tests, we did not think this would substantially impact results.  On average, each study took 40 minutes to complete.  %The information in Table \ref{tbl:data} summarises the captured metrics for each participant.


%\begin{table*}[htbp]
%\small
%\begin{center}
%\begin{tabular}{|r|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|p{0.3cm}|}
%\hline
%Participants & 1 &2&3&4&5&6&7&8&9&10&11&12&13&14&15&16&17&18&19&20\\
%\hline\hline
%gender&f&m&f&f&f&f&f&m&f&f&m&f&m&f&m&m&m&m&m&m\\
%A condition first task &y&y&y&n&n&y&n&n&y&y&n&n&y&y&n&n&n&n&n&n\\
%\hline\hline
%A Condition: task &4&2&3&4&3&&2&1&4&1&4&1&3&2&3&2&1&4&3&2\\
%paper used&n&n&n&n&n&n&y&n&y&y&n&y&n&n&y&n&n&n&n&n\\
%charts used &1&2&2&0&2&4&5&0&0&0&2&3&2&0&0&0&3&3&4&1\\
%maps used &1&1&2&2&2&1&1&0&1&0&1&1&2&1&0&1&0&0&2&1\\ 
%same as used &4&3&3&6&0&2&0&2&1&0&6&5&6&2&7&0&6&7&7&7\\
%\# data sources used &4&3&4&4&4&3&4&3&4&4&3&3&5&4&5&4&4&5&5&4\\
%chosen restaurant/uni &4.1&2.4&3.5&4.3&3.3&&2.4&1.4&4.2&1.6, \newline 1.3, \newline 1.2& 4.2& 1.4, \newline 1.5, \newline 1.3& 3.2& 2.1, \newline 2.3, \newline 2.6& 3.5, \newline 3.3&2.6, \newline 2.3, \newline 2.5&1.6, \newline 1.5, \newline 1.3&4.1&3.3&2.4, \newline 2.5, \newline 2.6\\
%\# factors in choice &6&5&4&4&2&4&8&8&6&3&4&8&5&4&7&7&4&5&5&5\\
%\hline\hline
% B Condition:task &3&&4&3&4&2&1&2&2&3&2&3&1&4&1&4&2&2&1&3\\
% paper used &n&n&n&n&n&n&y&n&y&y&n&y&n&y&y&n&n&y&n&n\\
%% spreadsheet/website&&&&&&&&&&&&&&&&&&&&\\
% number of spreadsheets used&5/5&4/4&2/5&1.5&2/5&5/5&4/4&2/4&3/4&&2/4&4/5&2/4&4/5&2/4&2/5&4/4&4/4&0&5/5\\
% number of websites used&1&1&4&3&3&0&2&3&2&&1&2&3&1&2&3&2&0&4&0\\
% chosen restaurant/uni&3.5&&4.2&3.3&4.3&2.1&1.4, \newline 1.2, \newline 1.6&2.1&2.3, \newline 2.6, \newline 2.5&3.5&2.2, \newline 2.3, \newline 2.6&3.5&1.1&4.1&1.6&4.2&2.6, \newline 2.3, \newline 2.5&2.3, \newline 2.5, \newline 2.6&1.1, \newline 1.3,  \newline 1.4&3.5\\
% \# factors in choice &4&3&2&3&1&6&5&7&7&5&4&7&6&3&6&4&3&6&4&5\\
% \hline
%\end{tabular}
%\end{center}
%\caption{Data collected from each of our trials, for each participant.} \label{tbl:data}
%\normalsize
%\end{table*}

\subsection{Task performance}

The following four sections describe the metrics we used to measure task performance.
%We used three metrics to measure task performance: time to completion; the number of factors used in the choice; and the number of candidates evaluated.

\subsubsection{Efficiency: Time taken}
Participants spent an average of 8.9 minutes performing the tasks. Condition A (DP) took slightly less time ($M=8.7$min, $SD=1.79$) per trial than condition B ($M=9.0$min; $SD=1.44$); however, a 2-way repeated measures ANOVA test of time taken by interface condition, blocked by participant ID, revealed that interface condition did not have a significant effect on task completion time.  This analysis also showed no significant effect of participant ID on task completion.  Comparing tasks, the restaurant selection task took on average slightly less time ($M=8.8$min,$SD=1.58$) than the university trials ($M=8.9$min,$SD=1.66$), but this difference was not significant. 

\subsubsection{Thoroughness: Factors weighed in final choice}
The second metric related to the number of factors each participant considered in making his or her final choice. To determine this, we asked participants to explain why they made their choice(s), and recorded the number of distinct data dimensions mentioned.  A 2-way ANOVA test of the effect of interface and participant ID on the number of factors mentioned revealed a significant effect; post-hoc analysis with Tukey-Scheff\'{e} adjustments indicated that participants in the DP condition mentioned significantly more factors ($M=5.5; SD=1.7$) than those in the control condition ($M=4; SD=1.73$), $F(1,19)=3.95; p<0.10$. A strong significant effect was also observed between participant ID and number of dimensions mentioned, meaning some participants mentioned significantly more factors than others ($F(19,19)=4.53; p < 0.001$).

\subsubsection{Diversity: Data sources consulted}
The third metric we employed to gauge the task performance was the number of different data sources consulted during the trial; our rationale for this metric was that more informed decisions derived from more thorough consideration of available data. In this metric, participants used an average of 88\% ($SD=0.13$) of data sources provided in the DP case, compared to 80\% ($SD=0.18$) in the control condition, although an ANOVA test blocking on participant ID demonstrated that interface choice only approached significance ($F(1,19)=0.04$ $p < 0.15$).

\subsubsection{Effort: External cognition}
Although we did not have an explicit measure of effort for this experiment (such as NASA's TLX \cite{tlx}) the use of paper notes provided an indicator of how much information participants had to keep track of during the study.  We found that participants took notes less on average (25\%) with the DP interface than the standard interface (35\%), a difference which approached significance in a 2-way ANOVA blocked by participant ID ($F(1,19)= 8.22; p\approx0.10$).

\begin{figure}[tbp]
\begin{center}
\includegraphics[width=8.5cm]{img/results}
\caption{\emph{Choice picks per participant trial} - Histogram of number of times each restaurant/university was chosen in DP interface (A condition) in blue/left bars, compared to the Excel/website (B condition) in red/to the right.}
\label{fig:chosen_results}
\end{center}
\end{figure}

\subsubsection{Candidate selection}
Since the tasks were subjective-choice, we could not evaluate the `correctness' of answers.  However, to determine whether there was a difference in variability of answers between interface conditions, we plotted the choices on a histogram for each trial, per task and dataset for both conditions, visible in Figure \ref{fig:chosen_results}.  As can be seen, there was less agreement among universities than restaurants, although little agreement overall in both conditions. This is likely due to the many subjective factors involved in such choice tasks.

\subsection{Strategies: Successive Elimination vs Tallying}
As described later in this section, we noticed several different strategies the participants used to evaluate each candidate selection. One common strategy was \emph{successive elimination}, that is, to regard a single dimension or factor at a time, starting with the most important, and ruling out candidates not meeting the minimum requirements for that value.  However, when there was no clear aspect that was ``most important'', this  ``greedy'' strategy can result in suboptimal decisions.  Another tactic, which we called \emph{tallying the pros and cons}, was to consider all candidate choices together, totalling up the advantages and disadvantages of each, potentially weighed by its perceived importance.  This strategy was less vulnerable to getting stuck in local maxima than the former.

To understand whether the interface influenced the choice of strategy, we measured the number of candidates the participant considered at their final choice.  This was a strong marker for use of each strategy; people who used the successive elimination strategy arrived with only 1--2 candidates at decision time, while those that tallied still maintained the entire starting set.\looseness=-1

We found that the use of DP strongly influenced people to keep all candidates around, while participants in the B condition eliminated choices early.  An ANOVA test demonstrated a significant effect between condition and number of candidates maintained; a post-hoc analysis with Tukey-Scheff\'{e} adjustments confirmed that the number of candidates used in the final choice for participants in the DP condition was greater ($M=5.85;SD=0.45$) than the control condition ($M=4.95; SD=2.26$) $F(1,19)=5.323; p<0.05$.

\subsection{Condition A: Use of Data Integration Features}

To determine whether participants used the data integration features of DP, we looked at use of the \emph{multi-path selection} and \emph{Same-As} features of the system.   Pertaining to path selection, all participants readily used the path selection process to select values.   Five participants (25\%) deliberately used multi-path selection, defined as selecting more than one active path per group at the same time to display common values across heterogeneous items. (We did not take into account accidental uses of multi-path, such as when a participant had an already active path and wanted to switch to a separate path accidentally).

Participants used the drag-and-drop \emph{Same-As} capability extensively. Sixteen (80\%) used \emph{Same-As} as least once; among these participants, they used \emph{Same-As} an average of 4.6 times per trial. We counted a single ``use'' as a single drag-and-drop of an individual item, or a drag-and-drop operation of an entire group onto another (we did not differentiate enumerated value consolidation from entity consolidation, as these are not discernibly different from the interface perspective).\looseness=-1

% we examined use on performance but nothing significant was found :/

\subsection{Use of Visualisation Features}
In our determination of the extent to which visualisation tools were used in condition A, 13 (65\%) used charting tools at least once, while a majority (15, 75\%) used the map.  To assess the impact use of these features had on performance, we carried out a multiple regression on the time taken, with the number of uses of charting and mapping as variables.  We found significant effects of both charting and mapping variables on time taken, ($R^2_{adj} = 0.04; F(2,17)=3.79; p<0.05$), with coefficients ($Y_0=8.91;\beta_{charts}=0.49;\beta_{maps}=-1.05$) demonstrating that charting positively influenced time taken, while the use of maps led to shorter times.

\subsection{Condition B: Results and Observations}
In condition B, participants were given the option of using websites and/or a spreadsheet containing the same data as condition A, to make their choices.  A mixed usage of websites and the spreadsheet was observed, and we measured the fraction of the trial time spent in Excel versus looking at the sites in a 5-value range (0,25,50,75,100\%).  Six individuals used Excel entirely (100\%) without consulting the websites, while one avoided Excel entirely. The uses of Excel for external cognition ranged from collation behaviour, to tallying annotations, to colour-coding cells for making easier the identification of  ``pros'' and ``cons''. In general, users struggled with both the websites and with the spreadsheet, although they could usually find the information they required after a short period of frustration. 



%In the B conditions, participants were given the option of using websites and/or a spreadsheet to make their choice.  For B trials, we measured the fraction of the trial time spent in Excel versus looking at the sites in a 5-value range (0,25,50,75,100\%).  Six individuals used Excel entirely (100\%) without consulting the web sites, while one avoided Excel entirely; most fell somewhere in between, with median use at 75\%.   When asked to explain their choice of tool post-hoc, participants who used Excel explained that it saved them time over individually searching and consolidating information from the websites (10 participants).  Participants used websites when they needed to know more than what was provided in the spreadsheets (8 participants), when they mistrusted the information in them (1 participant), or if they were not familiar with Excel (1 participant).

%Participants ran into a number of difficulties with the spreadsheet interface. Participants struggled with looking up values across different worksheets (data sources).  Some attempted to collate all data onto a single sheet, so that they could compare the values all at once; however, this approach was often error prone.  For example, two participants did not notice that the rows in two sheets were in different order, causing their pasted values to be incorrectly mapped.  Four participants struggled with sorting columns, and only 1 attempted charting (p7).  Although she attempted to plot multiple factors simultaneously, Excel's charting features caused her considerable difficulty and she eventually resorted at creating multiple simple bar-charts instead.

%While most participants only made minor formatting and column sizing changes to the worksheets to facilitate reading and interpretation,  four made extensive edits to the sheets to help them ``think through'' the task in various ways.  These uses of Excel for external cognition ranged from the collation behaviour just described to tallying annotations, to colour-coding cells to allow easy identification of  ``pros'' and ``cons''; ``I can't deal with so many textual values; I need colours to help me see'' (p6). Another user calculated their own weighted metric of which university to choose by averaging different metrics supplied by the data sources and filling in their own chosen weights.  

%%  was use of pen and paper to collate the values, which was often faster and resulted in less observed frustration. While the majority of users did not attempt anything complex with Excel (in fact only one user used charts), there was some advanced use of Excel observed.

%% todo - look up to make sure it was really p7 here 
%Various difficulties were also encountered with use of the websites. There was significant confusion over various attributes, especially in the University selection task.  For example, p15 could not tell how the teaching score from the Times Higher Education was calculated, in order to assess its relative importance.  Several participants had difficulty finding information they needed because of inconsistencies in site layout, especially finding course requirements, information that ``should be obvious''.  Similar issues were encountered with finding information in the restaurant condition; p7 said ``I wish they would put Cuisine Type in the same place for every restaurant - important information!'' Similarly, participants found it difficult to visualise the locations of restaurants in cities that they were not familiar, and could not find a way to easily map them. Overall, the users that spent the most time using websites exhibited significant frustration attempting to locate and compare different criteria (such as course entry requirements, or restaurant locations), and often ended up swapping back to using the supplied spreadsheets.


% Notably, a number of users admittedly introduced their own bias into the choices in both A and B conditions: ``I prefer Indian food, so I will choose the Indian restaurant'', and one participant spent time on Google Maps looking at the routes to each restaurant, and eliminating those that required bus transfers (the protocol did not mention routing/transfers at all).

\subsection{Survey Results}

\begin{figure}[tbp]
\begin{center}
\includegraphics[width=7.5cm]{img/survey}
\caption{\emph{Survey results} - Answers to questions on a 5-point Likert scale, from 1-\emph{strongly disagree} to 5-\emph{strongly agree}.}
\label{fig:survey}
\end{center}
\end{figure}

When asked to rate the DP interface in the exit survey, all participants responded that they felt they understood the system, with sixteen out of the twenty participants (80\%) responding that they agreed \emph{very strongly} that they felt they understood it.  Eighteen (90\%) reported that they thought  DP was \emph{easy}, as well as \emph{useful}, with one person being neutral on each.  As to the statement ``DP is confusing'',  11 (55\%) strongly disagreed, 6 (30\%) disagreed, and 3 (15\%) agreed.  On reviewing the time trials, we discovered that the 3 participants who rated DP as confusing completed the trials significantly more slowly than the rest of the group. The survey results were visualised in Figure \ref{fig:survey}.

% (ANOVA?)

%+What did people think about it? 
% Usefulness,Ease,Confusion,etc

The users also noted that they would use an interface like DataPalette in the future, for example, in finding a property to rent/buy, in choosing a job and for purchasing electronic devices.  Interestingly, one participant indicated that he/she would not use it for decisions such as selecting a restaurant, because ``it would cheapen the experience'' by removing the element of spontaneity of choice; they would use it, however, for making more ``important'' decisions.  As for ways to improve DP, the participants suggested making the origin of the information clearer, particularly when combining multiple data sources. The participants also requested the ability to sort instances, as well as explanations of ratings and scoring systems (however some of these are not even transparent on websites). Participants also requested standard features not present in our prototype, such as window management options (specifically, arranging and minimising windows), and the ability to undo operations.

\section{Discussion and Limitations}
In this section, we first revisit the three hypotheses introduced in Methodology, incorporating observations from the study's results to support views on each.  We follow this with a discussion of the limitations regarding the design of the interface, the state of the prototype, and the design and execution of the study.  Finally, we discuss our current and follow-on plans for continuing this line of research.

\subsection{Does DataPalette enable data integration?}
We set out to test three hypotheses with the DataPalette study. The first was that users would understand the interface mechanisms of DP (h1).  The second, h2, was that DP would enable people to mix and integrate heterogeneous data in the process of performing their tasks.  The third, h3, was that using DP would facilitate task completion.  
% Using real data obtained from typical data sources identified during our pre-study (PS.1), we tested the DP prototype and its integration interaction mechanisms with ``real'' users, who were students, staff and alumni of our University who had varying backgrounds and levels of expertise with computers.

The study produced substantial support for h1. All participants reported that they understood the tool, and that it was easy to use.   All participants managed to use the interface to view, organise and collate data without running into major roadblocks or confusion, and all effectively were able to compare multiple attributes of heterogeneous data items directly.  More than half of the participants used DP's visualisation features (charting or map) -- often several times during the trial -- suggesting that these features were useful and usable as well.  

Additional evidence that participants had a solid understanding of the system was reflected in their feedback, particularly in their requests for features and desired capabilities.  Several participants requested search functionality, sort and filter functionality, the ability to display multiple properties for a single instance simultaneously, and the ability to display multiple attributes together in a 2-or-3 dimensional visualisation.  Perhaps the most interesting suggestion was also the most common -- the ability to selectively view the provenance of information after instances were combined.  For example, after his trial, P15 said:

\begin{quote}
Properties are tricky. Sometimes you don't care [which data source] a property is from, like ``address'' or ``phone number'' - for these the way it's done now is fine. But in some cases you need context of where the properties come from in order to know what it really means - like for ``rating'', it makes a big difference whether you're talking about ``Yelp rating'' or some random reviewer's rating.  You also don't know what typical ratings are, whether 5 stars are much better than 4, etc.
\end{quote}

Pertaining to h2, all participants were able to work with multiple sets of heterogeneous data effectively.  With respect to integration specifically, a majority (80\%) of the participants successfully and deliberately integrated data using drag-and-drop SameAs capabilities.  While single-paths were readily used, multi-path features were not as widely used (only by 4 participants). We believe that participants may not have realised that creating multiple path selections per group was possible, instead assuming it to be similar to the single ``Current path'' state per window of most file managers. 

Assessing whether or not DP improved task performance (h3) was difficult, given the small sample size of our study, and the large number of factors influencing each person's choice.  Tasks were completed on average slightly faster than the control interface, but not significantly.  However, more data sources seemed to be consulted (we use ``seemed'' carefully because these findings approached significance) during trials with DP over the control interface, which meant that participants were looking at more diverse information than the control conditions.  We also found that participants justified their choices with a greater number of factors in DP than with the control interface, suggesting that their decisions may have been made considering a greater number of factors.  Participants entertained more possibilities for longer in the DP trial, while they were more prone to eliminate candidates early in the baseline interface.  Finally, people took fewer paper notes in the DP condition than with the baseline, suggesting that there was less need for external cognitive support in DP.\looseness=-1

%% -> discussion and limitations
\subsection{Design Limitations}
In addition to the aforementioned feature requests, we observed a number of potential areas for improvement in the design of the DP interface.  One such area pertained to window layout and screen real-estate management: participants were prone to opening up a large number of windows, including maps and charts.  When their workspaces started to fill up, we found that participants spent a lot of time arranging windows, and that they tended to forget what each window represented.  We plan to address these issues in the next version of DataPalette.

A key design decision we made at the outset was to target only the most common forms of heterogeneity observed in PS.2.  To expand DP's integration capabilities, we are considering a number of new interaction affordances for facilitating field combination and splitting, and unit of measure reconciliation.  This would cover a majority of the structural and modelling-oriented heterogeneity cases observed in DP.2.  Extending the ``Do What I Mean'' capabilities of the visualisation features to be unit-of-measure-aware, we believe, would be valuable to users.  A core problem with realising such an capability, however, is that few sources explicitly annotated data values with measurement units.

\subsection{Study Limitations}

Concerning limitations of the study, the small sample size of our study (20 participants) meant that we could not confirm some of the effects observed with statistical significance.  Second, providing participants a time limit of 10 minutes on trials may have affected the strategies they used to make their choices.  For this reason, in our follow-up study, we will give participants a greater amount of time for tasks of similar complexity.  A departure from realistic tasks was the way in which we pre-determined the data sources for participants to use.  We did this in order to focus participants' efforts on looking at and working with their choices, rather than retrieving them.  However, as supporting effective retrieval and serendipitous discovery will be important for DP to be useful in practice, we plan to look at supporting these stages in the future. 

% \subsection{Integration Limitations}
% In the A condition, where participants used DataPalette to complete their tasks, they used it to collate the data on-screen, and compare multiple values directly. About half of the observed users actually used the instance combination feature of DataPalette, with the other half able to successfully make decisions without using it. Those who tried to use it were largely successful, and were able to therefore use the global brush-highlighting to simultaneously compare different statistics. Most users instantly opened up all data sources into individual boxes, in order to determine which sources contained specific statistics. The result of this technique is that the users instantly filled their screen, and ran out of space for plots and maps.

%% \subsection{Better Supporting the Task}
%% - are people more thorough
%% - do they evaluate more sources

%% \subsection{Causing Less Frustration}

%% - Gave up with aspects of the tasks later / not at all
%% - With websites, users gave up on websites and moved on early

%% \subsection{Keeping an Open Mind}

%% - Did users rule out choices less/later
%% - Did that mean they chose "better" options

%% \subsection{What method did people use?}

%% - Processes
%% - Organisation of data/screen
%% - A vs B, how are they different?

% DAN's  qual analysis of processes
%% In order to complete the tasks, the users followed a number of different processes. The most common process followed
%% was {\it collation} of data, either on-screen or on paper. Some users were proficient enough to copy and paste data
%% in the supplied spreadsheets from worksheet to worksheet, while others manually typed data value-by-value across worksheets.
%% Others preferred to collate the data from screen to paper, in order to compare multiple data points. A similar process that
%% some participants followed was to determine which values of a particular statistic were acceptable, and keep a paper tally
%% of these next to the set of choices. They then made their choice based on the value of this tally.

%% Two contrasting approaches that participants followed was to use the data to rule out candidates, or to use the data to
%% directly compare candidates at once. Our pool of participants exhibited both behaviours evenly, however in the condition
%% when using the DataPalette interface, significantly more comparison (and visualisation of values) was performed, with fewer
%% participants using the ``ruling out'' process. A consequence of this was that when asked to justify their choices, users were
%% able to verify their values on-screen immediately, whereas those who had ruled-out had to memorise their reasons, with
%% mixed success  -- many participants had to look through the data sources to re-find the reasons why they has ruled out some choices.

%% Therefore, the uses that were using DataPalette were more confident in their choices, and knew exactly why they had chosen them,
%% often pointing to the screens to show and verify each choice as they explained them.

%What we found 
%
%What we didn't find (evidence for)
%
%What we might look at next -- follow-on work
%		We focused on terminological heterogeneity -- didn't address structural heterogeneity, semantic heterogeneity
%		We focused on finite (small) sets Streaming data (how do select future data --) 
%		Scale - small data, what are the facilities required for large data
%		Collaborative - how might interaction support multiple users collaborating?
%
%Limitations found from study... what is the take away from the limitations

\section{Conclusions} %Key findings of the whole paper and its implications

As expressed in Voltaire's poem \emph{La B\'{e}gueule}, ``the best is the enemy of the good'', we believe that the quest for fully-automatic, complete approaches to data integration have caused simpler, manual approaches to be overlooked.  Based upon the results of our investigation, we have seen a number of benefits to interactive, lightweight approaches over automatic and bespoke methods, at least for a frequently-occurring class of information gathering for decision-making tasks.

In particular, the results suggest that the key affordances for the suitability of such tools are flexibility, simplicity, and ease of use.  Just as work in the ``user-subjective approach'' to PIM (e.g., \cite{user-subjective}) showed that personal, user-specified attributes were ultimately the most useful, granting users the flexibility to combine or separate information items as needed allowed the tool to support the varied strategies participants employed to compare and examine their options. Second, the low cost of use  (in terms of time and effort required) meant that integration could be done (and undone) as appropriate throughout the ``inner loop'' of users' exploratory processes.  The reason this was significant was that this process itself determined, incrementally, the information and sources that were ultimately considered for the final decision. Therefore, any integration approach that required sources to be specified \emph{a priori}, or that was time or effort-intensive at each integration step, was simply not appropriate for this context.

Due to the promising findings of this study, we plan to continue investigating lightweight, \emph{in-situ} approaches to supporting ad-hoc data integration during the course of sense-making and decision-making activities.  In particular, we are examining gestural input methods for the purposes of supporting more fluid exploration and mixing.  On the basis of feedback from reviewers, we have also begun considering semi-automatic and crowd-powered methods to help users quickly resolve challenging reconciliation problems they might encounter.

% instead of being a separate step requiring pre-planning one that and that information sources could be brought in or removed as needed.

%% this study demonstrated that user-driven and-defined approach to information integration provided the flexibility to allow people to organise and support information gathering tasks in different ways.  The result, that  people weighed more factors from a greater number of information sources, while expending equal or less time and effort, demonstrated that such tools could broaden the information gathering capacities and allow people to make better use of available information sources during decision-making activities. 

%% this was having a sufficiently low barrier of effort to use, provided both the flexibility and facility to support information gathering tasks associated with decision-making activities.  The result was people weighed more factors from a greater number of information sources, broadening the scope of their information gathering for such decisions, while expending comparable or less effort and time.

%% Moreover, through our pre-studies and DataPalette evaluation, we have shown that much of heterogeneity exhibited by structured data feeds available on the Web today can be managed reasonably through easy to use, and intuitive interactive approaches for end-users. 

\section{Acknowledgements} 

The work presented in this paper was supported by the SOCIAM project, funded by the Engineering and Physical Sciences Research Council under contract EP/J017728/1. Dr Packer is grateful for funding from the EPSRC in the form of a Post Doctoral Award.  We would like to thank our collaborators Wendy Hall, mc schraefel, Tim Berners-Lee, Kieron O'Hara, Susan Davies, Maraim Elbadri, Tom Smith, Yang Yang, Igor Popov, and Shauna VanKleek whose help and advice have shaped this work throughout.

%% Just as the Italian in Voltaire's poem \emph{La Begueule} said ``the best is the enemy of the good'', we believe that the quest for complete approaches to data integration have perhaps caused less principled, ``ad-hoc'' approaches to be overlooked.  Based upon the results of our investigation, we see a number of benefits to lightweight, user-driven approaches to coping with heterogeneity over automatic and bespoke ones. Just as the \emph{user-subjective approach} to PIM \cite{user-subjective} showed that subjective labels and attributes were more useful than physical ones for files and folders, a user-controlled approach to data integration, where data may be combined (and separated) at will may benefit the sensemaking or decision-making process.   Towards this end, our results of our pre-studies and DataPalette show that, for a majority of the kinds of structured data feeds available on the Web today, the kinds of heterogeneity can be largely managed using simple interactive approaches that are intuitive and preceived as useful by end-users. 

%%  things as simple as coreference involved any subjective judgement, 

%% the ability to  In our investigation we found that complete approaches to data integration

% - data integration literature demands `correct' but perfect is the enemy of the good.
% ``perfect'' be the enemy of the good
%% In this paper, we take the position that there is a need for a difference in focus between the approaches taken to data integration between the approaches taken in database integration and that of PIM, because of vast differences in requirements.  In database systems, the overall objective is usually to allow multiple large databases to be accessed as if one. This requires essentially full mapping of all data types and objects and well-defined semantics concerning where and how data gets converted. The upfront costs of such complete integration are typically high, but are typically justified in the long-term, high-volume use cases imagined. In typical sense-making scenarios of PIM, however, people might need to combine information from multiple sources for a one-off task; meaning that any upfront cost would directly impact the time and effort a person has allocated for their task.  Moreover, while a fully, uniform query capability might be nice, such capability is likely of less overall importance for a single quick task than simply being able to quickly and easily identify and cope with differences.
% Just as journalism became peer-produced with the explosion of blogging, data journalism is on the brink of moving from skilled data analysts the likes of The Guardian Datablog staff\footnote{Guardian Datablog - \url{http://www.guardian.co.uk/news/datablog}} into the hands of the ordinary citizen \cite{datajournalismhandbook}.  In order for this to happen, however, tools that allow people to effectively combine data more effectively than current structured PIM tools and generic spreadsheet tools will become increasingly important. 

%% Just as journalism became peer-produced with the explosion of blogging, data journalism is on the brink of moving from skilled data analysts the likes of The Guardian Datablog staff\footnote{Guardian Datablog - \url{http://www.guardian.co.uk/news/datablog}} into the hands of the ordinary citizen \footnote{Data Journalism Hand Book: \url{datajournalismhandbook.org}}.  In order for this to happen, however, tools that allow people to effectively combine data more effectively than current structured PIM tools and generic spreadsheet tools will become increasingly important. 

%% \section{Acknowledgments}


% Balancing columns in a ref list is a bit of a pain because you
% either use a hack like flushend or balance, or manually insert
% a column break.  http://www.tex.ac.uk/cgi-bin/texfaq2html?label=balance
% multicols doesn't work because we're already in two-column mode,
% and flushend isn't awesome, so I choose balance.  See this
% for more info: http://cs.brown.edu/system/software/latex/doc/balance.pdf
%
% Note that in a perfect world balance wants to be in the first
% column of the last page.
%
% If balance doesn't work for you, you can remove that and
% hard-code a column break into the bbl file right before you
% submit:
%
% http://stackoverflow.com/questions/2149854/how-to-manually-equalize-columns-
% in-an-ieee-paper-if-using-bibtex
%
% Or, just remove \balance and give up on balancing the last page.
%
\balance

% If you want to use smaller typesetting for the reference list,
% uncomment the following line:
\small
\bibliographystyle{acm-sigchi}
\bibliography{carpedata}
\end{document}
