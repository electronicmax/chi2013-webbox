\documentclass{sigchi}

% Use this command to override the default ACM copyright statement (e.g. for preprints). 
% Consult the conference website for the camera-ready copyright statement.
%% \toappear{
%% Permission to make digital or hard copies of all or part of this
%% work for personal or classroom use is granted without fee provided that 
%% copies are not made or distributed for profit or commercial advantage and
%% that copies bear this notice and the full citation on the first page. To
%% copy otherwise, or republish, to post on servers or to redistribute to 
%% lists, requires prior specific permission and/or a fee.\\
%{\confname{CHI'13}}, May 5--10, 2012, Austin, Texas, USA.\\
%Copyright 2012 ACM 978-1-4503-1015-4/12/05...\$10.00.
%}

% Arabic page numbers for submission. 
% Remove this line to eliminate page numbers for the camera ready copy
%\pagenumbering{arabic}


% Load basic packages
\usepackage{balance}  % to better equalize the last page
\usepackage{graphics} % for EPS, load graphicx instead
\usepackage{times}    % comment if you want LaTeX's default font
\usepackage{url}      % llt: nicely formatted URLs

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\bf\ttfamily}}}
\makeatother
\urlstyle{leo}


% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, 
% to give it a fighting chance of not being over-written, 
% since its job is to redefine many LaTeX commands.
\usepackage[pdftex]{hyperref}
\hypersetup{
pdftitle={SIGCHI Conference Proceedings Format},
pdfauthor={LaTeX},
pdfkeywords={SIGCHI, proceedings, archival format},
bookmarksnumbered,
pdfstartview={FitH},
colorlinks,
citecolor=black,
filecolor=black,
linkcolor=black,
urlcolor=black,
breaklinks=true,
}

% create a shortcut to typeset table headings
\newcommand\tabhead[1]{\small\textbf{#1}}


% End of preamble. Here it comes the document.
\begin{document}

\title{Carp\'{e} Data: Supporting Serendipitous Data Integration in Personal Information Management}

\numberofauthors{3}
\author{
  \alignauthor 1st Author Name\\
    \affaddr{Affiliation}\\
    \affaddr{Address}\\
    \email{e-mail address}\\
    \affaddr{Optional phone number}
  \alignauthor 2nd Author Name\\
    \affaddr{Affiliation}\\
    \affaddr{Address}\\
    \email{e-mail address}\\
    \affaddr{Optional phone number}    
  \alignauthor 3rd Author Name\\
    \affaddr{Affiliation}\\
    \affaddr{Address}\\
    \email{e-mail address}\\
    \affaddr{Optional phone number}
}

% Teaser figure can go here
%\teaser{
%  \centering
%  \includegraphics{Figure1}
%  \caption{Teaser Image}
%  \label{fig:teaser}
%}

\maketitle

\begin{abstract}

\end{abstract}

\keywords{}

\category{H.5.m.}{Information Interfaces and Presentation (e.g. HCI)}{Miscellaneous}

\terms{Human Factors; Design; Measurement.}

\section{Introduction}

In recent years, an unprecedented quantity and variety of information has been made available as structured data on the Web, through APIs, datasets, and data feeds.  This information includes access to data previously hidden behind services and applications, such as retailer product catalogues, information not previously directly released to the public, such as open government data or records of personal financial transactions, and new kinds of data generated by emerging kinds of data sources, such as wearable and smartphone-based biosensors.  

While a primary goal of opening up such direct access to information is the hope that end-user citizens will make more informed decisions pertaining to their health, wealth, or well-being \cite{}, use of this data beyond specialised app developers, journalists and other “data specialists” remains minimal.  Our hypothesis is that the main impediment towards end-user access to this data is a mismatch between the capabilities of tools currently used to satisfy daily information needs, and those required to effectively browse, use and consume heterogeneous structured data from diverse sources.  For example, while much of this data represents a many and varied set of things, activities, and descriptions at various granularities, most commonly used structured personal information management (PIM) tools either can only manage a small, fixed set of data types (such as digital calendaring tools and  to-do list managers) or provide little or no support for structured data at all, such as text editors and sketching/drawing tools \cite{}.    

If PIM tools were extended to enable end-users to make effective use of the emerging ecosystem of personal data, how would this impact personal information practice? This paper presents our initial results towards answering this question through a multi-method investigation of the personal data integration problem.  We start with a small interview study examining information tasks people perform that rely on multiple sources of information, and how such needs are currently satisfied.  Our results suggest that people prefer to rely upon multiple, diverse sources to singular integrated ones for a number of reasons, including coverage, reliability, and seeking out more suitable alternatives.  Second, we conduct a analysis of various popular personal data sources available today to identify barriers to effective unification of data from each.  We draw upon definitions and work from the database integration systems literature to characterise types of heterogeneity exhibited across data sources in three popular domains: social networking, shopping, and dining, finding that terminological heterogeneity dominates the simpler data feeds (including social networking and restaurant recommendations), while structural issues pervade the more complex schemas of online retailers' product catalogues.

Based upon the data integration needs revealed by people in the interviews, and the kinds of heterogeneity observed in the data feeds, we embarked on a user-centric design exercise towards an interface to facilitate simple, ``light-touch'' integration tasks of diverse, heterogeneous data sources.  We describe our initial foray into this exercise, an interface we call DataPalette, which focuses on the most common types of heterogeneity to enable serendipitous ``data mixing'' - a form of simple integration sufficient to let people easily and effectively combine and compare information sources without the need to write code.  Our usability evaluation of DataPalette reveals that most users were comfortable with and that this interface is effectively expedites the most sophisticated of the typical kinds of ``data integration'' tasks people need to perform while planning personal,

\section{Background}

In this section, we touch on motivating work for DataPalette from three fields: database integration, peronal information management, and end-user mashups and toolkits.

The primary motivation for this work stems from field studies in personal information management, where effectively consolidating and
combining data from multiple sources has been a major recurring theme. The problem of data fragmentation (\cite{Jones05towardsa}, for example, arises, in part, from a failure of PIM tools to adequately support the effective consolidation of data across multiple applications, services and platforms (e.g., \cite{bergman},  \cite{boardmansasse}). In our own previous field study, (reference anonymised) we observed several different variations of manual ``coping strategies'' (or, if programmers, elaborate, custom-coded one-off solutions) that people devised to merge in data from external sources -- be them online, offline, or other people.  Similar findings from other studies include Voida et al.'s observations of volunteer coordinators' ``homebrew databases'', manually-mainted information assemblages concocted to handle the widely varied and heterogeneous data collection requirements such groups needed to coordinate their activities \cite{Voida:2011:HDC:1978942.1979078}. 
%% TODO MORE HERE

%% don't like the beginning of this > 
It became clear that effectively coping with data heterogeneity would be a central focus to letting people effectively draw upon multiple, arbitrary sources of data when consulting the theoretical data integration literature. Alon Halvey describes hetereogeneity as an inevitable by-product of the distributed processes that are used to author it:

\begin{quote} 
[The problem stems from the fact that] we are trying to integrate data systems that were developed for slightly (or vastly) different business needs. Hence, even if they model overlapping domains, they will model them in different ways. Differing structures are a byproduct of human nature ?people think differently from one another even when faced with  the same modeling goal. \cite{alonhalevy}
\end{quote}

In this paper, we take the position that there needs to be a difference in focus between the data integration approaches discussed in the databases literature and that of PIM, because of corresponding differences in requirements.  In database systems, the overall objective is usually to allow multiple large databases to be accessed as if one.
This requires essentially full mapping of all data types and objects and well-defined semantics concerning where and how data gets converted.  The upfront costs of such complete integration are typically high, but are typically justified in the long-term, high-volume use cases imagined. In typical sensemaking scenarios of PIM, however, people might need to combine information from multiple sources for a one-off task; meaning that any upfront cost would be
fully consume the time and effort a person has allocated for their task.  Moreover, while a fullly, uniform query capability might be nice, such capability is likely of less overall importance for a single quick task than simply being able to quickly and easily identify and cope with differences.

A number of prototype PIM systems have demonstrated the kinds of
capabilities that effective management of data heterogeneity can provide for users. The SEMEX \cite{semex} and Haystack \cite{haystack} systems,

The mash-up

\section{Pre-study 1 - Understanding Heterogeneity for Everyday Tasks}
\subsection{Method}
Our pre-study investigated the types of tasks people perform online that required heterogeneous data sources, and which tools they would use to organise a large social event involving 15 or more people.  We interviewed 8 participants, using a general interview guide approach based loosely on a set of questions (see Appendix ?).  This approach allowed both the participant and interviewer a degree of freedom in conversation and each interview could adapt to the participant’s experiences, while collecting the same general areas of information.  Each interview was recorded and notes taken, the interviewer was trained so that they were knowledgeable about the importance of the study and to minimise bias.
\subsection{Results and Discussion}
The participant demographic consisted of 8 people, 7 of which were male and 1 female.  They were split evenly into two age groups of 18-25 and 26-32.  All but one participant used social network sites very regularly, and they either logged in multiple times a day, left a website page open or used dedicated application for their social networking site’s updates.  Those that used social networking websites primarily use Facebook.  All of the participants used Twitter to listen to broadcasted tweets, and 6 out of 8 people regularly tweeted. 

Question 1: Tasks
All participants had experience in using multiple websites to complete tasks.  They listed example tasks such as shopping (including food, consumer electronics, hotels and flights), searching for jobs, choosing recipes, study and work.  The biggest focus for shopping focused tasks was balancing price, quality and speed of delivery.  In general, people did not not trust a single websites for reviews because they said that they could be biased and did not always review the features they were interested in.  One participant said that video reviews of items were really important because they showed the aesthetics and scale of the item.  In general for initial research into organising a task it was typical to Google keywords to find related websites to their tasks.  They identified that they used different website for different jobs, such as manufacturers website for technical details, review aggregators for a range of opinions, and Google maps for location based decisions.  Social networks were also identified to have different functions, such as different groups of people belong to each and share different types of opinions.  One participant said that they shared their outlook and gmail calendars, but only for work events and did not record social activities on them.

Question 2: Large Social Event
All of the participants would organise a large social event by talking to their friends, about their ideas, preferences and recommendations.  The tools they would use to acquire this information included face-to-face, phone calls, email, Skype, Facebook events.  The method chosen depended on the time scale required to organise an event, in general if there was a short time scale people would speak in person or on the phone.  Otherwise, people would set up a FaceBook event page to discuss ideas with their friends.  If their friends were not on Facebook they would email them.  All but one participant said they would not use Doddle to organise day and time of an event, because they felt that people did not fill in the form and it was more suit to organising work event not social.  

Most people felt that being assertive and posting their decisions about the date and time on Facebook meant that organising events were more successful than trying to gather a consensus.  They expected that their friends would voice any objections if they could not attend or like the restaurant or activity selected.   They selected venues, locations, restaurants and activities based on their own knowledge, friend’s recommendations, Google maps, reviews through Googling and review sites such as tripadvisor.  People stated that the cost, price and easy to get to locations were the most important factors when choosing a venue.  They considered how to get there and looked up train or bus times on the Web.  One participant organised carpools informally and at last minute via Facebook or text messages.

When organising an event the weather was not that important because it they did not trust its accuracy for events plan further in the future than one week.  Also, their friend’s preferences in price and food choices were not a priority; they would try to be inclusive but only if it meant small changes to the plan.  Choosing food and timings were often made on-the-fly, by either with the use of mobile applications or by walking past a location.
\subsection{Prestudy 1 Summary of Findings}
People said that they would like a website that could support the evolution of an event, that allowed them to post drafts of an event.  They felt that organising an event should be a process that changes over time and did not need rushing.  Three of the participants said that they would like a recommendation system for places to eat and activities. Another strong requirement was that it had to be ubiquitous so that everyone could use it because they wanted a single place to communicate with their friends.  While Facebook was the most popular social networking site for organising events, half of the participants felt that it was not the best solution and would prefer a collaborative environment, which could be wiki based.

\section{Prestudy 2 : Technical Challenges of Integrating the Data}

\subsection{Method}

\subsection{Results}

\subsection{Analysis}

\subsection{Prestudy 2 Summary of Findings}

\section{WebBox Interface - Design of the DataPalette}

Design Goals, 
	What are the problems observed needed to address
	What kind of interactions can be designed to solve them?

Interaction features 
	multiple paths selection
	sameas interactions
	visualisation of partial results

Design process

\section{Methodology}

\subsection{Participants}We recruited 20 participants (10 female) from the University of Southampton’s international student mailing list.  All of the participants spoke English, and for 12 of them, English was not their first language, however they had all passed the university English proficiency test.  Predominately the participants were studying various levels of Computer Science, and 5 of which studied other subjects.  All of the participants had previously encountered tasks requiring them to use and evaluate data from multiple websites.\subsection{Task Design}We designed a semi-structured lab-based study around four possible tasks shown in Table \ref{tab:studyfactors}.  The tasks were to select a restaurant for an event or university at which to study, out of six possible choices. We selected a shortlist of six because it is typical for users to narrow down their options to a limited selection before analysing the details of their final choices. The shortlist of universities and restaurants were taken from the top six ranked from the Complete University Guide (for task 1 and 2), Tripadvisor (for task 3) and Yelp (for task 4).  The top six were chosen from these websites because they provide a realistic shortlist and are comparable in terms of rankings and properties. The web sites used as data sources were chosen because they are the most popular and contain comparable statistics for universities and restaurants.
\begin{table*}[t]
\caption{Tasks, choices and data sources}
\begin{center}

\begin{tabular}{|p{4cm}|p{6cm}|p{6cm}|}
\hline
Task	 &Choices	&Data Sources\\
\hline
1) Three universities they would apply to study Sport Science & Universities: 1) Loughborough,  2) Durham,  3) Exeter, 4) Edinburgh, 5) Birmingham, and 6) Bath & http://www.thecompleteuniversityguide.co.uk/, http://www.ucas.ac.uk/, http://unistats.direct.gov.uk/, http://www.timeshighereducation.co.uk/world-university-rankings/ \\
\hline
2) Three universities they would apply to study History & Universities: 1) Cambridge, 2) London School of Economics and Political Science, 3) Durham, 4) Oxford, 5) St Andrews, and 6) University College London & http://www.thecompleteuniversityguide.co.uk/, http://www.ucas.ac.uk/, http://unistats.direct.gov.uk/, http://www.timeshighereducation.co.uk/world-university-rankings/ \\
\hline
3) Restaurant they would book for 12 friends in Cambridge&Restaurants : 1) Alimentum, 2) Gardenia Restaurant, 3) The Cambridge Chop House, 4) Al Casbah, 5) Midsummer House Restaurant, and 6) Nando's Restaurant. & www.yelp.co.uk, www.tripadvisor.co.uk, http://ratings.food.gov.uk/, facebook and google plus.\\
\hline
4) Restaurant they would book for 12 friends in Glagow & Restaurants :1) Black Sheep Bistro, 2) Charcoals, 3) Number 16 Family Restaurant, 4) Fanny Trollopes Cafe, 5) Two Fat Ladies At The Buttery, and 6) Sapori D'Italia. & www.yelp.co.uk, www.tripadvisor.co.uk, http://ratings.food.gov.uk/, facebook and google plus.\\
\hline
\end{tabular}
\end{center}
\label{tab:studyfactors}
\end{table*}%Each task had an A and B condition.  The A condition, the participant could only use WebBox to make their decision; and in the B condition the participant was given the choice to using any websites they desired and or spreadsheets in Microsoft Excel containing the data taken from the data sources to make their choice.  Each study consisted of two tasks, one A and one B condition.  Each participant was given 10 minutes to complete a task.  In order to select which tasks the participant was given, we used a latin square to permutate the tasks and conditions.  In order to train the user on how to use our interface, they viewed a five-minute WebBox tutorial video introducing its basic functionality, how to use histograms and maps, and linking instances.\subsection{Data Collection}Each study was overseen by a facilitator and an observer:  the role of the facilitator was to explain the study’s protocol to the participant and to answer any questions; and the role of the observer was to observe without interacting with the user, and to take notes.  During the lab study, we recorded the audio and the participant’s actions on screen. We asked the participants to speak out loud their thought process and what they were looking at, so that we could evaluate their reasoning behind their processes.The studies lasted 40 minutes, on average.  Both the facilitator and observer were trained on the purpose of the study, their role and how they could and couldn’t influence the study.  The studies were run over 4 days.  At the end of each day the facilitators and observers met to discuss the studies’ data and to revisit protocols, if necessary.\subsection{Data Analysis}During the data collection we collated a spreadsheet summarising the participant’s gender, typical daily computer usage, the tasks allocated and basic actions performed during the task.  After we had collected the study’s data, we performed our data analysis. 

TODO look further into types of data analysis....

\subsection{Hypotheses}
Interaction-method specific hypotheses
\begin{itemize}
	\item h1.1 - Do people understanding the problem of co-reference, and the need to reconcile coreference problems?
	\item h1.2. Does the ability to do drag + drop combination for co-reference reconciliation effectively solve this problem?
	\item h2.1- Do people understand the problem of structural differences in data?
	\item h2.2 - Does multipath selection let people effectively deal with this -- and work with collections of heterogeneous items?
\end{itemize}
Are these interaction methods sufficient to perform common tasks involving heterogeneous data sources?  Does supporting these simple techniques facilitate task completion?

\section{Results}
How many native english speakers, only 8 were all enrolled at university all past proficiency test.
\section{Discussion}
What we found 

What we didn’t find (evidence for)

What we might look at next -- follow-on work
		We focused on terminological heterogeneity -- didn’t address structural heterogeneity, semantic heterogeneity
		We focused on finite (small) sets Streaming data (how do select future data --) 
		Scale - small data, what are the facilites required for large data
		Collaborative - how might interaction support multiple users collaborating?

Limitations found from study... what is the take away from the limitations
\section{Conclusion} %Key findings of the whole paper and its implications


\section{Acknowledgments}


% Balancing columns in a ref list is a bit of a pain because you
% either use a hack like flushend or balance, or manually insert
% a column break.  http://www.tex.ac.uk/cgi-bin/texfaq2html?label=balance
% multicols doesn't work because we're already in two-column mode,
% and flushend isn't awesome, so I choose balance.  See this
% for more info: http://cs.brown.edu/system/software/latex/doc/balance.pdf
%
% Note that in a perfect world balance wants to be in the first
% column of the last page.
%
% If balance doesn't work for you, you can remove that and
% hard-code a column break into the bbl file right before you
% submit:
%
% http://stackoverflow.com/questions/2149854/how-to-manually-equalize-columns-
% in-an-ieee-paper-if-using-bibtex
%
% Or, just remove \balance and give up on balancing the last page.
%
\balance

% If you want to use smaller typesetting for the reference list,
% uncomment the following line:
% \small
\bibliographystyle{acm-sigchi}
\bibliography{carpedata}
\end{document}
